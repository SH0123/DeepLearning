{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd36Mk/c2LwodPG6Nyu6ES",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SH0123/DeepLearning/blob/master/logisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTSiEqdYCdnI",
        "colab_type": "code",
        "outputId": "49be6be4-7dae-43f8-be91-8bb4fa304acd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4a7614e310>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpMu76mNCqba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.sigmoid(self.linear(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytCaIeRATqn4",
        "colab_type": "code",
        "outputId": "50be48f9-74cb-4082-89ac-a42cc03969d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "x_data = torch.FloatTensor([[1, 2], [2, 3], [3, 1], [4, 3], [5, 3], [6, 2]])\n",
        "y_data = torch.FloatTensor([[0], [0], [0], [1], [1], [1]])\n",
        "\n",
        "model = BinaryClassifier()\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    hypothesis = model(x_data)\n",
        "\n",
        "    cost = F.binary_cross_entropy(hypothesis, y_data)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "        correct_prediction = prediction.float() == y_data\n",
        "        accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f} Accuracy {:2.2f}%'.format(\n",
        "            epoch, nb_epochs, cost.item(), accuracy * 100\n",
        "        ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/100 Cost: 0.778947 Accuracy 33.33%\n",
            "Epoch   10/100 Cost: 0.606802 Accuracy 66.67%\n",
            "Epoch   20/100 Cost: 0.446548 Accuracy 66.67%\n",
            "Epoch   30/100 Cost: 0.376169 Accuracy 83.33%\n",
            "Epoch   40/100 Cost: 0.318945 Accuracy 83.33%\n",
            "Epoch   50/100 Cost: 0.268428 Accuracy 83.33%\n",
            "Epoch   60/100 Cost: 0.222594 Accuracy 100.00%\n",
            "Epoch   70/100 Cost: 0.183695 Accuracy 100.00%\n",
            "Epoch   80/100 Cost: 0.158160 Accuracy 100.00%\n",
            "Epoch   90/100 Cost: 0.144616 Accuracy 100.00%\n",
            "Epoch  100/100 Cost: 0.134716 Accuracy 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsGhuUBoVLbP",
        "colab_type": "code",
        "outputId": "45c7a965-15e2-4186-983f-3907c0816e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "#Cross Entropy Loss(low level)\n",
        "\n",
        "z = torch.rand(3, 5, requires_grad=True)\n",
        "hypothesis = F.softmax(z, dim=1)\n",
        "\n",
        "#[3,]\n",
        "y = torch.randint(5, (3,)).long()\n",
        "\n",
        "y_one_hot = torch.zeros_like(hypothesis)\n",
        "#[3, 5]\n",
        "y_one_hot.scatter_(1, y.unsqueeze(1), 1)\n",
        "\n",
        "#[3, 1]\n",
        "cost = (y_one_hot * -torch.log(hypothesis)).sum(dim=1)\n",
        "\"\"\"\n",
        "F.nll_loss(F.log_softmax(z, dim=1), y)로 나타낼 수 있음\n",
        "F.cross_entropy(z, y)가 가장 간단\n",
        "\"\"\"\n",
        "#scalar\n",
        "cost = cost.mean()\n",
        "\n",
        "print(hypothesis)\n",
        "print(y)\n",
        "print(y_one_hot)\n",
        "print(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2528, 0.1500, 0.2019, 0.1292, 0.2662],\n",
            "        [0.1518, 0.2729, 0.1887, 0.1441, 0.2425],\n",
            "        [0.1761, 0.2659, 0.1987, 0.2173, 0.1420]], grad_fn=<SoftmaxBackward>)\n",
            "tensor([0, 3, 0])\n",
            "tensor([[1., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0.],\n",
            "        [1., 0., 0., 0., 0.]])\n",
            "tensor(1.6830, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrczUtlLVm04",
        "colab_type": "code",
        "outputId": "06815b4f-232f-4f0d-e59b-b4fbdf15f6c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#Training Cross Entropy Loss(high level)\n",
        "\n",
        "class SoftmaxClassifierModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(4, 3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "x_train = torch.FloatTensor([[1, 2, 1, 1],\n",
        "                            [2, 1, 3, 2],\n",
        "                            [3, 1, 3, 4],\n",
        "                            [4, 1, 5, 5],\n",
        "                            [1, 7, 5, 5],\n",
        "                            [1, 2, 5, 6],\n",
        "                            [1, 6, 6, 6],\n",
        "                            [1, 7, 7, 7]])\n",
        "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])\n",
        "\n",
        "model = SoftmaxClassifierModel()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    pred = model(x_train)\n",
        "    cost = F.cross_entropy(pred, y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/1000 Cost: 1.193624\n",
            "Epoch  100/1000 Cost: 0.647261\n",
            "Epoch  200/1000 Cost: 0.559104\n",
            "Epoch  300/1000 Cost: 0.503264\n",
            "Epoch  400/1000 Cost: 0.458217\n",
            "Epoch  500/1000 Cost: 0.418269\n",
            "Epoch  600/1000 Cost: 0.380891\n",
            "Epoch  700/1000 Cost: 0.344497\n",
            "Epoch  800/1000 Cost: 0.307935\n",
            "Epoch  900/1000 Cost: 0.271172\n",
            "Epoch 1000/1000 Cost: 0.243551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5hAFDVOUGT-",
        "colab_type": "text"
      },
      "source": [
        "multi layer perceptron을 통해 XOR 문제 해결"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7YaUyQZae9h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "9aa4ac8e-c2b5-4981-ec57-9175415ab37f"
      },
      "source": [
        "x = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = torch.FloatTensor([[0], [1], [1], [0]])\n",
        "\n",
        "class MultiPercep(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(2, 2, bias=True)\n",
        "        self.linear2 = nn.Linear(2, 1, bias=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.percep = nn.Sequential(self.linear1, self.sigmoid, self.linear2, self.sigmoid)\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = self.percep(input)\n",
        "\n",
        "        return output\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "model = MultiPercep()\n",
        "optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "\n",
        "nb_epochs = 10000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    hypothesis = model(x)\n",
        "    cost = criterion(hypothesis, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(epoch, cost.item())\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.728512167930603\n",
            "1000 0.023579902946949005\n",
            "2000 0.006828591227531433\n",
            "3000 0.003952228929847479\n",
            "4000 0.00277394475415349\n",
            "5000 0.002134685404598713\n",
            "6000 0.0017338610487058759\n",
            "7000 0.0014592853840440512\n",
            "8000 0.0012595225125551224\n",
            "9000 0.0011076723458245397\n",
            "10000 0.0009883784223347902\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THoQ-mQ6XQeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}